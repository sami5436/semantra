{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1dbf82e8",
   "metadata": {},
   "source": [
    "### 4d_summarize_results.ipynb  \n",
    "Passes the validated chunks back to LLaMA for final summarization.  \n",
    "Formats a clean final answer for the user along with context references."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81b13b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOllama\n",
    "from langchain.schema import SystemMessage, HumanMessage\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b2950e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/90/p8kgtvm572d51cr90k19v_580000gn/T/ipykernel_8110/368174091.py:1: LangChainDeprecationWarning: The class `ChatOllama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import ChatOllama``.\n",
      "  llm = ChatOllama(model=\"llama3\")\n"
     ]
    }
   ],
   "source": [
    "llm = ChatOllama(model=\"llama3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2f7bcb",
   "metadata": {},
   "source": [
    "create embedder object + load vectordb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44ad455c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/90/p8kgtvm572d51cr90k19v_580000gn/T/ipykernel_8110/2066271422.py:1: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embedder = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
      "/opt/anaconda3/envs/ig-reel-env/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "embedder = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "vectorstore = FAISS.load_local(\"vectorstore/\", embeddings=embedder, allow_dangerous_deserialization=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86992af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"battery duration of hip and ankle configurations\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2503ce2",
   "metadata": {},
   "source": [
    "same process (this needs to be replaced and held in state when doing langgraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dfceb5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = vectorstore.similarity_search(query, k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a668c4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_text = \"\\n\\n\".join([f\"[chunk {i+1}]\\n{doc.page_content}\" for i, doc in enumerate(matches)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3188a5",
   "metadata": {},
   "source": [
    "craft rlly good prompt LOL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bfd5e6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    SystemMessage(\n",
    "        content=(\n",
    "            \"You are a helpful assistant. Given a user query and some context chunks, \"\n",
    "            \"summarize the answer clearly and concisely. If the context is unclear, say so.\"\n",
    "        )\n",
    "    ),\n",
    "    HumanMessage(\n",
    "        content=(\n",
    "            f\"User query: {query}\\n\\n\"\n",
    "            f\"Context chunks:\\n{retrieved_text}\\n\\n\"\n",
    "            \"Please provide a concise answer. You may mention which chunk(s) supported your response.\"\n",
    "        )\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "faa94518",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = llm.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2c06eede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "According to the provided context, the battery duration of hip-and-ankle configurations is 25 minutes before reaching 50% of the voltage capacity (~900 mAh). This information can be found in Chunk 1.\n",
      "\n",
      "Additionally, when configured for simultaneous assistance to both hip and ankle joints, the device was able to operate for approximately 35 minutes (Chunk 3).\n"
     ]
    }
   ],
   "source": [
    "print(response.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ig-reel-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
